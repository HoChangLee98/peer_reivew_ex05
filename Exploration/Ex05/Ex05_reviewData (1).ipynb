{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비, 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # [[YOUR CODE]]\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    x_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        x_train.append(temp_X)\n",
    "\n",
    "    x_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        x_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(x_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "        # vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def train_wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNUSED>'] for word in wordlist]\n",
    " \n",
    "    def test_wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "        \n",
    "    x_train = list(map(train_wordlist_to_indexlist, x_train))\n",
    "    x_test = list(map(test_wordlist_to_indexlist, x_test))\n",
    "        \n",
    "    return x_train, np.array(list(train_data['label'])), x_test, np.array(list(test_data['label'])), word_to_index\n",
    "        \n",
    "x_train, y_train, x_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "데이터셋 내 문장 길이 분포\n",
    "적절한 최대 문장 길이 지정\n",
    "keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n",
    "'''\n",
    "\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', \n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', \n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 구성 및 validation set 구성 (3가지 이상 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136182, 41)\n",
      "(136182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 4)           40000     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 42,417\n",
      "Trainable params: 42,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "(1) 1D CNN\n",
    "'''\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 4   \n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(2) GlobalMaxPooling1D()\n",
    "'''\n",
    "\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(3) LSTM\n",
    "'''\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "266/266 [==============================] - 5s 7ms/step - loss: 0.4816 - accuracy: 0.7857 - val_loss: 0.3510 - val_accuracy: 0.8481\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8579 - val_loss: 0.3379 - val_accuracy: 0.8542\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3155 - accuracy: 0.8679 - val_loss: 0.3396 - val_accuracy: 0.8532\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3040 - accuracy: 0.8722 - val_loss: 0.3406 - val_accuracy: 0.8521\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2927 - accuracy: 0.8783 - val_loss: 0.3442 - val_accuracy: 0.8533\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2828 - accuracy: 0.8831 - val_loss: 0.3552 - val_accuracy: 0.8469\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2744 - accuracy: 0.8869 - val_loss: 0.3483 - val_accuracy: 0.8508\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2644 - accuracy: 0.8916 - val_loss: 0.3516 - val_accuracy: 0.8524\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2562 - accuracy: 0.8957 - val_loss: 0.3622 - val_accuracy: 0.8501\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2482 - accuracy: 0.8991 - val_loss: 0.3659 - val_accuracy: 0.8504\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2412 - accuracy: 0.9019 - val_loss: 0.3803 - val_accuracy: 0.8472\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2336 - accuracy: 0.9051 - val_loss: 0.3891 - val_accuracy: 0.8474\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9080 - val_loss: 0.4030 - val_accuracy: 0.8471\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2206 - accuracy: 0.9108 - val_loss: 0.4082 - val_accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2164 - accuracy: 0.9126 - val_loss: 0.4128 - val_accuracy: 0.8450\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9151 - val_loss: 0.4240 - val_accuracy: 0.8452\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2050 - accuracy: 0.9172 - val_loss: 0.4214 - val_accuracy: 0.8442\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.1992 - accuracy: 0.9201 - val_loss: 0.4344 - val_accuracy: 0.8455\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.1929 - accuracy: 0.9229 - val_loss: 0.4438 - val_accuracy: 0.8446\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.1885 - accuracy: 0.9248 - val_loss: 0.4459 - val_accuracy: 0.8423\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.4747 - accuracy: 0.8381\n",
      "[0.4746701121330261, 0.838090181350708]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수화 시도한 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "i3c4cyYH7hop"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 처리해야 할 문장을 리스트 타입 변수에 저장\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "\n",
    "def split_sentence_to_word(sentences) : # 문장을 단어 단위로 분리하는 메소드\n",
    "  element_to_string = ' '\n",
    "  word_list = []\n",
    "\n",
    "  # list type에 저장된 문장을 인자로 받음\n",
    "  for index in range(len(sentences)) :\n",
    "    print(f\"{sentences[index]} 을(를) 단어 단위로 쪼개는 중 ...!\")\n",
    "    element_to_string = sentences[index]\n",
    "    word_in_sentence = sentences[index].split()\n",
    "    for i in range(len(word_in_sentence)) :\n",
    "      word_list.append(word_in_sentence[i])\n",
    "\n",
    "  word_list = list(set(word_list))  # 중복 단어 제거\n",
    "  print(word_list)\n",
    "  return word_list\n",
    "\n",
    "\n",
    "\n",
    "def words_to_dict(word_list) :\n",
    "\n",
    "  index_to_word={}  # 빈 딕셔너리 생성\n",
    "\n",
    "  # 단어들 채우기\n",
    "  # 관례: <BOS>, <PAD>, <UNK>가 딕셔너리 맨 앞\n",
    "  index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "  index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "  index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "\n",
    "  for index in range(len(word_list)) :\n",
    "    index_to_word[index+3] = word_list[index]\n",
    "\n",
    "  print(index_to_word)\n",
    "  return index_to_word\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxsd27pQBzyF",
    "outputId": "8475bc83-d3ca-472d-b03b-703cef4041d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry 을(를) 단어 단위로 쪼개는 중 ...!\n",
      "i eat lunch 을(를) 단어 단위로 쪼개는 중 ...!\n",
      "now i feel happy 을(를) 단어 단위로 쪼개는 중 ...!\n",
      "['feel', 'i', 'hungry', 'now', 'eat', 'happy', 'lunch']\n"
     ]
    }
   ],
   "source": [
    "word_list = split_sentence_to_word(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTDziAUtCoaL",
    "outputId": "650a9d84-1f72-45c9-b09c-26cb678add32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'feel', 4: 'i', 5: 'hungry', 6: 'now', 7: 'eat', 8: 'happy', 9: 'lunch'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word = words_to_dict(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwyLA-vDEZhu",
    "outputId": "83b9bfe6-839f-4e69-c667-17c58bc14810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'feel': 3, 'i': 4, 'hungry': 5, 'now': 6, 'eat': 7, 'happy': 8, 'lunch': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}  # 텍스트 데이터 -> 숫자 변환 method\n",
    "print(word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMWC4e7aE-Pf",
    "outputId": "927b1002-fa2f-4217-a26c-9260cb0a8c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 예시 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4fB_6U4FASU",
    "outputId": "93678bc3-0c1b-48fd-af5e-a4c426b3b8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다.\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7s1eZ6vHZEu",
    "outputId": "8130cc1c-ce42-411c-d4ca-20498a8901c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 3, 5], [1, 4, 7, 9], [1, 6, 4, 3, 8]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다.\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다.\n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNhFhkCFHmh7",
    "outputId": "60960519-b77b-4056-9d8e-874086000014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lunch hungry feel\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다.\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1,9, 5, 3], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZh8byEdHnvw",
    "outputId": "5b87f3dd-9156-47ad-9587-38cb038e37cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다.\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkALprC7H0j6"
   },
   "source": [
    "# 2. Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnU43VCQHvKT",
    "outputId": "35266497-b281-45d9-ea1f-ea223654a703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 3 5 0]\n",
      " [1 4 7 9 0]\n",
      " [1 6 4 3 8]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def embedding_text_to_wordVector(word_vector_dim, sentences, word_to_index): # 숫자로 변환된 텍스트 데이터에 Embedding 레이어를 적용하는 method\n",
    "  vocab_size = len(word_to_index)\n",
    "\n",
    "  embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "  # embedding layer 적용\n",
    "  raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "\n",
    "  raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "  print(raw_inputs)\n",
    "\n",
    "\n",
    "embedding_text_to_wordVector(4, sentences, word_to_index) # 4차원 워드벡터 가정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSfYkiWiIHkD",
    "outputId": "34b260fc-a123-4da4-ed2b-3229ab9e83f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.00523763 -0.02910571 -0.02028175  0.03832351]\n",
      "  [-0.03667934  0.04875101  0.01472544  0.00644764]\n",
      "  [ 0.00687833  0.04088802  0.00649511 -0.03485214]\n",
      "  [-0.02126306 -0.02149533 -0.00320364 -0.02279295]\n",
      "  [-0.02982663 -0.03327595 -0.04593907 -0.04785801]]\n",
      "\n",
      " [[-0.00523763 -0.02910571 -0.02028175  0.03832351]\n",
      "  [-0.03667934  0.04875101  0.01472544  0.00644764]\n",
      "  [-0.02432516  0.01223282  0.02596812  0.04905364]\n",
      "  [-0.04542078  0.00711315 -0.0475868  -0.01422922]\n",
      "  [-0.02982663 -0.03327595 -0.04593907 -0.04785801]]\n",
      "\n",
      " [[-0.00523763 -0.02910571 -0.02028175  0.03832351]\n",
      "  [-0.01564812 -0.00911261 -0.04923382  0.03126277]\n",
      "  [-0.03667934  0.04875101  0.01472544  0.00644764]\n",
      "  [ 0.00687833  0.04088802  0.00649511 -0.03485214]\n",
      "  [ 0.02019985  0.03662732  0.03049115  0.04110719]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야\n",
    "# embedding 레이어의 input이 될 수 있음에 주의\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxyMiVZUJ3fT"
   },
   "source": [
    "# 3. 다양한 신경망 시도해보기 (Text Classification 태스크)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsNe9gZwKmfO"
   },
   "source": [
    "## 1) 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "mRMl7O04JswC",
    "outputId": "d180a8f5-a47f-46be-89ab-91ad83cad7ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다.\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCmOCTGuLXg3"
   },
   "source": [
    "## 2) GlobalMaxPooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "RxJvpc7YLQpu",
    "outputId": "9553f3bb-dc31-4129-9427-7ad6f6f2fc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다.\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsDMw4P5LjCM"
   },
   "source": [
    "## 3) Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tQ7dj6e6LZiG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "n3xbcC7qL2-5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다.\n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "WrrWISZyL6S8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43/209606989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'의'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'가'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'이'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'은'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'들'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'는'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'좀'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'잘'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'걍'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'과'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'도'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'를'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'으로'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'자'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'에'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'와'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'한'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'하다'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# [[sample CODE]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_words' is not defined"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=num_words):\n",
    "    # [[sample CODE]]\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any')\n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any')\n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEkUbnc4MBxm"
   },
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다.\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다.\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다.\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다.\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
